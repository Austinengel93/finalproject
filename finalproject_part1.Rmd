---
title: "Final Project"
author: "Tunan, Austin, Avi"
date: "Your Submission Date Here"
output: html_notebook
---
# Alternate Grading System
## By Tunan, Austin, Avi

### 1. DATA

**Give a description of the data you chose to analyze. Include anything you know about the source of the data (who generated, in what context, doing what activities) and its structure (what does each column and row represent). Include code that shows a useful illustation of the data (you could do this by showing the head of the data, or listing all column names, or using the glimpse function)**

Data History

This data came from “OLI Elementary Chinese I” online course at Carnegie Mellon University from Jan 15, 2006 - Dec 11, 2006. “OLI”--Open Learning Initiative is a grant-funded group at Carnegie Mellon University, offering innovative online courses to anyone who wants to learn or teach. “Elementary Chinese I” aims to help beginners develop communicative competence in the basic four skills (listening, speaking, reading and writing) and culture of Chinese. The course curriculum is organized around the 5 Cs principles of the National Standards for Foreign Language Education for the 21st Century – Communication, Cultures, Comparisons, Connections and Communities. “Elementary Chinese I” covers 8 units. The principal investigator was Suemei Wu. 

Data Description

General Info

Number of students = 23, Number of unique steps = 255, Total number of steps = 3500, Total number of transactions = 6457, Total number of student hours = 38.51, Knowledge Component Models = 5 which are 1. Defalut(21 KCs) 2. Item model (255 KCs) 3. Single KC(1 KC) 4.Unique step(255 KCs) 5. Unique step new(255 KCs)

Dataset info

Row: Each row represents a specific question answered by a specific student

Column: There are total 33 columns. 

Row : Row no.
Sample : Sample of the data from where this dataset is selected here is is All data
Anon Student Id : Online Id generated by the student 
Problem Hierarchy : Unit and section to which problem belongs to
Problem Name : Unique name of the problem which is in the system
Problem View : Problem view no. Which is 1 for every row in this case
Problem Start Time: Start time of the problem along with date
Problem End Time : End time of the problem along with date
Latency (sec) : Time duration spent on that problem by the student
Steps Missing Start Times : This represents the no. of steps which are missing the start time recorded by the system
Hints : No. of hints  used
Incorrects : No. of incorrect answers submitted
Corrects :No. of correct answers submitted for that question
Avg Corrects :Average of number of correct answer submitted
Steps : No. of problem steps
Avg Assistance Score :Because the problems in this course were set as, if the answer was wrong, it would automatically provided hint and another attempt, this column is the combination of hints and incorrects. 
Correct First Attempts : If Correct answer submitted at first attempt (boolean)
Condition : blank column
KCs (Default) :No. of KCs from Default category
Steps without KCs (Default) : Steps without any KC from defalut category
KC List (Default) : List of KC from default category,specifies the name of the KC
KCs (Item Model): No. of KCs from Item Model category
Steps without KCs (Item Model): Steps without any KC from Item model category
KC List (Item Model):  List of KC from Item model category, specifies the name of the KC
KCs (Single-KC) : No. of KCs from Single KC category
Rest all of the columns related similar to the columns related to KCs as above.

### 2. QUESTION

**Can we develop a comprehensive grading system based on multiple factors instead of just numbers of correct answers and how is it different from the traditional grading system?**

### 3. APPROACH
**To solve this problem our approach is that first we will calculate the base grade the normal way, in this case as the student is getting question correct after certain hints and attempts so we are calculating 'base grade'according to the number of questions got correct in first attempt and how many attempted. Then we will find a modified grade which wiil take not only these two factors but other factors as well. The model to calculate modified grade is as follows:

If the student gets question right in 1st attempt = 1 point
If the student gets question right in 2nd attempt = 0.8 points
If the student gets question right in 3rd attempt = 0.5 points
If the student gets question right in 4th attempt = 0 Points

Also 

If the time taken per attempt is less than 15 secs( why?explained in the code below) bonus of 0.2 points, else 0

Then we will compare the grades of the students to see whether upto what extent these factors contribute to the new grading system. We are developing this new grading system because we feel that cuurent grading system fails to capture certain aspects of learning and the varaibles which we have chosen to develop new grading explain us about the adaptiveness, grasp and comprehension of the students over the problems.

### 4. PROCESS, RESULTS & INTEPRETATION
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("readxl")
install.packages("knitr")
```


#Import data from excel
```{r}
#import "Originaldata.xlsx"
library(dplyr)
library(readxl)
Dataset1 <- read_excel("Originaldata.xlsx")
Dataset1
```

#Change certain variables from character to numeric for the later calculation purpose
```{r}
library(readxl)
Dataset2 <- read_excel("Originaldata.xlsx", 
    col_types = c("text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "numeric", "text", "numeric", "text", 
        "text", "text", "text", "numeric", 
        "numeric", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text"))
View(Dataset2)
```


#Change column names
```{r}
#When import the original dataset, the headers are somehow appear in the first row and the in the header row, it shows "x__1","x__2" all the way to "x__32".To change back the real headers, we rename each columns. 


colnames(Dataset2)<-c("Quesno.","Sample","AStuId","PH","PN","PV","PST","PET","Latency","SMST","Hints","Incorrects","Corrects","AvgCorrects","Steps","Attempts","Correct_in_First_Attempt","Condition","KCsD","SwKCsD","KClistD","KCsIM","SwKCsIM","KClistIM","KCsSKC","SwKCsSKC","KClistSKC","KCsUs","SwKCsUs","KClistUs","KCsUsn","SwKCsUsn","KClistUsn")
colnames(Dataset2)
Dataset2
```

#Delete the first row to avoid "n/a" error

```{r}
#After changing certain columns from character to numeric, the mislocated headers mention above (shown in the first row instead of in the header row) changed to "n/a". Also, after rename each column, there are two rows presenting the same content (headers). In order to successfully do calculation in later steps as well as avoid duplicated names, the first row need to be deleted. 

Dataset3 <- Dataset2[-c(1), ]
Dataset3
```


#Delete unrelated variables
```{r}
#based on team's former analysis, only save "Quesno.","AStuId", "Latency", "Hintsused","Attemptsused", "Correct_in_First_Attempt"

#Create a new dataset: Dataset4
Dataset4 <- select(Dataset3,Quesno.,AStuId, Latency, Hints, Attempts, Correct_in_First_Attempt)
Dataset4

```

#Finding the number of questions answered
```{r}

Dataset5 <- as.data.frame(table(Dataset4$AStuId))
names(Dataset5)[1] <- 'AStuId'
names(Dataset5)[2] <- 'Total_Questions_Answered'

```

#Finding the number of questions answered correctly
```{r}
Dataset6 <- aggregate(Correct_in_First_Attempt~AStuId,data=Dataset4,FUN=sum)
```

#Calculating Base grade.Also a bit of more cleaning as we don't want big Anonymous student id's in our dataframe,so converting those id's to simple S1, S2, S3.. and so on
```{r}
Dataset7 <- merge(Dataset5, Dataset6, by="AStuId")
Dataset7 <- data.frame(lapply(Dataset7, as.character), stringsAsFactors=FALSE)
Dataset7$AStuId[Dataset7$AStuId=="Stu_08e80173bfe563cdaa1c51c3af183967"]<- "S1"
Dataset7$AStuId[Dataset7$AStuId=="Stu_0ca6c119fbc68309999c206abd6f6ce8"]<- "S2"
Dataset7$AStuId[Dataset7$AStuId=="Stu_20d015855bc9af67db1dc0feece33671"]<- "S3"
Dataset7$AStuId[Dataset7$AStuId=="Stu_29b6513f433dd556e3d2fd0c84ae1df7"]<- "S4"
Dataset7$AStuId[Dataset7$AStuId=="Stu_319a6ee2e48581a4911c6683ce38e66c"]<- "S5"
Dataset7$AStuId[Dataset7$AStuId=="Stu_38cc777ed5f1e4b1ee746787c3481d1c"]<- "S6"
Dataset7$AStuId[Dataset7$AStuId=="Stu_471da3aff346f24618e1b39a406a58cc"]<- "S7"
Dataset7$AStuId[Dataset7$AStuId=="Stu_537005374fa63386664e733eaa39a5e2"]<- "S8"
Dataset7$AStuId[Dataset7$AStuId=="Stu_5d32ab292b6894e8033f88d311c06934"]<- "S9"
Dataset7$AStuId[Dataset7$AStuId=="Stu_6f55653c379702a86c4cbf2f51223235"]<- "S10"
Dataset7$AStuId[Dataset7$AStuId=="Stu_76666c42b3bd62de26ef1075eeef2441"]<- "S11"
Dataset7$AStuId[Dataset7$AStuId=="Stu_77c9bcf1bd70d48b86557417affc8df5"]<- "S12"
Dataset7$AStuId[Dataset7$AStuId=="Stu_7c4f0c44b1530b231566e556afa1cdde"]<- "S13"
Dataset7$AStuId[Dataset7$AStuId=="Stu_7eeb4ea1ffb99f1ac3fed64192efd6d9"]<- "S14"
Dataset7$AStuId[Dataset7$AStuId=="Stu_82a5861804e0ea0912a99785eafdca34"]<- "S15"
Dataset7$AStuId[Dataset7$AStuId=="Stu_a641820befdca79ef8f74204af4bba6f"]<- "S16"
Dataset7$AStuId[Dataset7$AStuId=="Stu_ac395ff9f20429c1ecf7514e25c73f9a"]<- "S17"
Dataset7$AStuId[Dataset7$AStuId=="Stu_bdb07906752e4574c1a601326d4f4ec8"]<- "S18"
Dataset7$AStuId[Dataset7$AStuId=="Stu_c2dcd451a79cf7af8bc88a06e3c99f96"]<- "S19"
Dataset7$AStuId[Dataset7$AStuId=="Stu_c33a255f6fb92612765666934486c872"]<- "S20"
Dataset7$AStuId[Dataset7$AStuId=="Stu_d6c50e4a6ca0f6eee2ce1903ecc1a3e4"]<- "S21"
Dataset7$AStuId[Dataset7$AStuId=="Stu_f45af1c4bd5b0e6d14621a4fc92b48c7"]<- "S22"
Dataset7$AStuId[Dataset7$AStuId=="Stu_f50a6fe4716e01ce297055b1a6990d26"]<- "S23"

#
Dataset7[,2] <- as.numeric(as.character(Dataset7[,2]))
Dataset7[,3] <- as.numeric(as.character(Dataset7[,3]))
Dataset7$Percentage <- with(Dataset7 , (Percentage = Correct_in_First_Attempt/Total_Questions_Answered ))
```

```{r}
Dataset7$Grade <- ifelse(Dataset7$Percentage >=0.9, "A",ifelse(Dataset7$Percentage >=0.8,"B",ifelse(Dataset7$Percentage >=0.6 & Dataset7$Percentage>= 0.7 ,"C","D")))
Dataset7
```

#Now we will find the modfied grade considering the other factors as well. These factors will be attempts, average time taken per attempt
```{r}
#removing the rows where latency(time taken for question)is very high number. The high numbers are unusual cases. Unusual in the sense that student has either left the tab or some othe reason.

D8 <- Dataset4
D8 <- subset(D8, Latency < 1000)
D8 <- data.frame(lapply(D8, as.character), stringsAsFactors=FALSE)
D8$AStuId[D8$AStuId=="Stu_08e80173bfe563cdaa1c51c3af183967"]<- "S1"
D8$AStuId[D8$AStuId=="Stu_0ca6c119fbc68309999c206abd6f6ce8"]<- "S2"
D8$AStuId[D8$AStuId=="Stu_20d015855bc9af67db1dc0feece33671"]<- "S3"
D8$AStuId[D8$AStuId=="Stu_29b6513f433dd556e3d2fd0c84ae1df7"]<- "S4"
D8$AStuId[D8$AStuId=="Stu_319a6ee2e48581a4911c6683ce38e66c"]<- "S5"
D8$AStuId[D8$AStuId=="Stu_38cc777ed5f1e4b1ee746787c3481d1c"]<- "S6"
D8$AStuId[D8$AStuId=="Stu_471da3aff346f24618e1b39a406a58cc"]<- "S7"
D8$AStuId[D8$AStuId=="Stu_537005374fa63386664e733eaa39a5e2"]<- "S8"
D8$AStuId[D8$AStuId=="Stu_5d32ab292b6894e8033f88d311c06934"]<- "S9"
D8$AStuId[D8$AStuId=="Stu_6f55653c379702a86c4cbf2f51223235"]<- "S10"
D8$AStuId[D8$AStuId=="Stu_76666c42b3bd62de26ef1075eeef2441"]<- "S11"
D8$AStuId[D8$AStuId=="Stu_77c9bcf1bd70d48b86557417affc8df5"]<- "S12"
D8$AStuId[D8$AStuId=="Stu_7c4f0c44b1530b231566e556afa1cdde"]<- "S13"
D8$AStuId[D8$AStuId=="Stu_7eeb4ea1ffb99f1ac3fed64192efd6d9"]<- "S14"
D8$AStuId[D8$AStuId=="Stu_82a5861804e0ea0912a99785eafdca34"]<- "S15"
D8$AStuId[D8$AStuId=="Stu_a641820befdca79ef8f74204af4bba6f"]<- "S16"
D8$AStuId[D8$AStuId=="Stu_ac395ff9f20429c1ecf7514e25c73f9a"]<- "S17"
D8$AStuId[D8$AStuId=="Stu_bdb07906752e4574c1a601326d4f4ec8"]<- "S18"
D8$AStuId[D8$AStuId=="Stu_c2dcd451a79cf7af8bc88a06e3c99f96"]<- "S19"
D8$AStuId[D8$AStuId=="Stu_c33a255f6fb92612765666934486c872"]<- "S20"
D8$AStuId[D8$AStuId=="Stu_d6c50e4a6ca0f6eee2ce1903ecc1a3e4"]<- "S21"
D8$AStuId[D8$AStuId=="Stu_f45af1c4bd5b0e6d14621a4fc92b48c7"]<- "S22"
D8$AStuId[D8$AStuId=="Stu_f50a6fe4716e01ce297055b1a6990d26"]<- "S23"
D8[,3] <- as.numeric(as.character(D8[,3]))
D8[,4] <- as.numeric(as.character(D8[,4]))
D8[,5] <- as.numeric(as.character(D8[,5]))
D8[,6] <- as.numeric(as.character(D8[,6]))

#Putting the no. of attempts in one column when the student has got question correct in first attempt.
D8$Attempts[D8$Correct_in_First_Attempt==1] <- 1
D8$timeperattempt <- with(D8, (timeperattempt = Latency/Attempts))
x <-median(D8$timeperattempt,na.rm = FALSE)
x
y <- mean(D8$timeperattempt,na.rm = FALSE)
y
#some values for 'timeperattempt' variable have come out to be 'zero' even though the student has got question right in the first attempt. This seems to be a bit odd. So considering the fact that student has got the question correct we are assigning that value to be median value, as we would be using 15 secs(which is close to median) as value to be the threshold value in our model to decide modified grade.

D8$timeperattempt[D8$timeperattempt==0] <- 12

w <-median(D8$Attempts,na.rm = FALSE)
z <- mean(D8$Attempts,na.rm = FALSE)
w
z
```

```{r}
#Assigning modified score(Score1) based on number of attempts according to rule 'No. of attempts = 1 =1 point,No. of attempts = 2 =0.8 points,No. of attempts = 3 = 0.5 points,No. of attempts = 4 or more =0 points'. This gives us a quadratic equation. We did not want a liner curve for this score.
D8$Score1 <- NA
D8$Score1[D8$Attempts ==1] <-1
D8$Score1[D8$Attempts ==2] <-0.8
D8$Score1[D8$Attempts ==3] <-0.5
D8$Score1[D8$Attempts >=4] <-0
D8
```

```{r}
#Assigning modified score (score2) based on the timeperattempt variable according to the rule'if time per attempt is less than 15 secs then bonus of 0.2 points othewise no bonus points.'
D8$Score2 <- NA
D8$Score2[D8$timeperattempt <= 15] <-0.2
D8$Score2[D8$timeperattempt  >15] <-0

#fiding final score i.e score1 + score2

D8$finalmodifiedscore <- with(D8, (finalscore = Score1 + Score2))
D9 <- aggregate(finalmodifiedscore~AStuId,data=D8,FUN=sum)
D10 <- merge(D9,Dataset7,by="AStuId")
D10$modifiedPercentage <- with(D10 , (modifiedPercentage = finalmodifiedscore/Total_Questions_Answered ))

#finding final grade
D10$modifiedGrade <- ifelse(D10$modifiedPercentage >=0.9, "A",ifelse(D10$modifiedPercentage >=0.8,"B",ifelse(D10$modifiedPercentage >=0.6 & D10$modifiedPercentage>= 0.7 ,"C","D")))
D10 <- subset(D10, Total_Questions_Answered > 50)

```

```{r}
Dfinalcomparison <- D10
Dfinalcomparison
```
### 5. CONCLUSION: 
Based on our analysis, a lot more students ended up with A’s than the baseline data set of unaltered grades, going from 2 all the way up to 10 students earning A’s, most of who were in the B or C range previously. The two important results were the elimination of the C grade and the reduced number of D’s from 5 to 3. While these show that our system has promise, since the point of this new grading system was to help more accurately reflect student performance based on factors outside of the binary right or wrong, automatically boosting half of the remaining students to the highest grade may not be the best solution. This could have happened for two possible reasons: the first is that we may have put too much emphasis on the speed at which the questions is answered, which was the only way to gain an increase in points. The second is that there may have been a factor in the data that we overlooked.

### 6. REFLECTION

The first major hurdle that we faced as a group was finding the right data. Originally, we wanted to work with data from 538, but, while interesting, did not apply to learning analytics. Thanks to Avi, we started to work with data from Carnegie Mellon’s online courses. The second issue that we came across was working with functions we were not completely familiar with. Thankfully, Google is a wonderful resource. The third issue was finding the best values to affect a students grade. The values changed based on what we thought would work best, but ultimately it ended up being a gradient curve based on the number of attempts the learner would make and how long they would take to get the correct answer to the question.  If we had more time, we would want to do a decision tree on figuring out which aspect of our new grading system have the most impact on helping a borderline student succeed and which have the least. We would also keep trying different values for altering the grades to make it have a more balanced distribution.



